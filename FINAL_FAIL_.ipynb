{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR10_CNN_init_b10456066.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"Hr6uu3lMzh0M","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import cv2\n","import numpy as np\n","import random as rn\n","import tensorflow as tf\n","import threading\n","import time\n","\n","global n_classes, b_count, b_count2, seq1, seq2, train_phase\n","ema_gp = []\n","train_phase = True\n","n_classes = 100\n","b_count = 0\n","b_count2 = 0\n","seq1 = np.asarray(np.zeros((50000)), np.int64)\n","for i in range(50000):\n","  seq1[i]=i\n","rn.shuffle(seq1)\n","\n","seq2 = np.asarray(np.zeros((10000)), np.int64)\n","for i in range(10000):\n","  seq2[i]=i\n","rn.shuffle(seq2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FHXjAL2SOWcT","colab_type":"code","colab":{}},"source":["\"\"\"\"\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\"\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o2KPUELMOsV3","colab_type":"code","outputId":"790d28ae-045c-4dd1-a179-6a5a7245a178","executionInfo":{"status":"ok","timestamp":1561223505100,"user_tz":-480,"elapsed":3624,"user":{"displayName":"Ziyitwo Zhuang","photoUrl":"","userId":"03996255233484029580"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["!mkdir -p drive\n","\n","!google-drive-ocamlfuse drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["fuse: mountpoint is not empty\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wyEhNlDlzh0P","colab":{}},"source":["_weights = {\n","        'wc1': tf.Variable(tf.truncated_normal([5, 5, 3, 36], stddev=0.05)),\n","        'wc2': tf.Variable(tf.truncated_normal([5, 5, 36, 96], stddev=0.05)),\n","        'wc3': tf.Variable(tf.truncated_normal([3, 3, 96, 128], stddev=0.05)),\n","        'wc4': tf.Variable(tf.truncated_normal([3, 3, 128, 256], stddev=0.05)),\n","        'wc5': tf.Variable(tf.truncated_normal([3, 3, 256, 256], stddev=0.05)),\n","        'wd2': tf.Variable(tf.truncated_normal([512, 512], stddev=0.05)),\n","        'out': tf.Variable(tf.truncated_normal([512, n_classes], stddev=0.05))\n","    }\n","_biases = {\n","        'bc1': tf.Variable(tf.truncated_normal([36], stddev=0.1)),\n","        'bc2': tf.Variable(tf.truncated_normal([96], stddev=0.1)),\n","        'bc3': tf.Variable(tf.truncated_normal([128], stddev=0.1)),\n","        'bc4': tf.Variable(tf.truncated_normal([256], stddev=0.1)),\n","        'bc5': tf.Variable(tf.truncated_normal([256], stddev=0.1)),\n","        'bd2': tf.Variable(tf.truncated_normal([512], stddev=0.1)),\n","        'out': tf.Variable(tf.truncated_normal([n_classes], mean=0.1, stddev=0.1))\n","    }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z-Oekfd9zh0Q","colab":{}},"source":["def relu(x,name=\"activation\"):\n","    return tf.nn.relu(x, name=name)\n","    \n","def conv2d(name, l_input, w, b, s, p, scope):\n","    l_input = tf.nn.conv2d(l_input, w, strides=[1,s,s,1], padding=p, name=name)\n","    l_input = l_input+b\n","    l_input = relu(l_input)\n","\n","    return l_input\n","\n","def max_pool(name, l_input, k, s):\n","    return tf.nn.max_pool(l_input, ksize=[1, k, k, 1], strides=[1, s, s, 1], padding='VALID', name=name)\n","\n","def norm(l_input, lsize=4, name=\"lrn\"):\n","    return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=name)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"94VSiHqhzh0S","colab":{}},"source":["   \n","def alex_net(_X, _dropout, batch_size):\n","    conv1 = conv2d('conv1', _X, _weights['wc1'], _biases['bc1'], 3, 'SAME', 'conv1')\n","    pool1 = max_pool('pool1', conv1, k=3,s=2)\n","    conv2 = conv2d('conv2', pool1, _weights['wc2'], _biases['bc2'], 1, 'SAME', 'conv2')\n","    pool2 = max_pool('pool2', conv2, k=3,s=2)\n","    conv3 = conv2d('conv3', pool2, _weights['wc3'], _biases['bc3'], 1, 'SAME', 'conv3')\n","    conv4 = conv2d('conv4', conv3, _weights['wc4'], _biases['bc4'], 1, 'SAME', 'conv4')\n","    conv5 = conv2d('conv5', conv4, _weights['wc5'], _biases['bc5'], 1, 'SAME', 'conv5')\n","    # Find current size of conv5 to fit the requirement of FC1.\n","    sizes = conv5.get_shape().as_list()\n","    neurons =  sizes[1]*sizes[2]*sizes[3]\n","    dense1 = tf.reshape(conv5, [batch_size, neurons]) # Reshape conv5 output to fit dense layer input\n","    wei_den1 = tf.Variable(tf.truncated_normal([neurons, 512], stddev=0.01))\n","    b_den1 = tf.Variable(tf.truncated_normal([512], stddev=0.1))\n","    \n","    dense1 = relu(tf.matmul(dense1, wei_den1) + b_den1, name='fc1') # Relu activation\n","    dd1=tf.nn.dropout(dense1, _dropout)\n","    dense2 = relu(tf.matmul(dd1, _weights['wd2']) + _biases['bd2'], name='fc2') # Relu activation\n","    dd2=tf.nn.dropout(dense2, _dropout)\n","    out = tf.matmul(dd2, _weights['out']) + _biases['out'] # Relu activation\n","\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tCNUC9U1zh0U","colab":{}},"source":["\n","\n","#--------建立讀取圖檔方法 opencv read img & reshape32*32 灰階----- \n","def getimagedictandreshape(train_image_dir):     #圖檔位置\n","    global imagee,res\n","    imagee=cv2.imread(train_image_dir,cv2.IMREAD_GRAYSCALE)\n","    #res=cv2.resize(imagee,(32,32),interpolation=cv2.INTER_CUBIC)\n","    \n","    return imagee\n","#--------\n","\n","def train_image_label_list(train_list, train_image_dir):\n","    f = open(train_list,'r')\n","    filenames = []\n","    labels = []\n","    \n","    for line in f:\n","      filename, label = line[:-1].split(' ')\n","      filename = train_image_dir+filename\n","      filenames.append(filename)\n","      labels.append(int(label))\n","      \n","    return filenames, labels\n","\n","  \n","def test_image_filename_list(train_list, train_image_dir):\n","    f = open(train_list,'r')\n","    filenames = []\n","    labels = []\n","    \n","    for line in f:\n","      filename= line[:-1]\n","      filename = train_image_dir+filename\n","      filenames.append(filename)\n","      #labels.append(int(label))\n","      \n","    return filenames, labels\n","\n","\n","def write_labeled_image_list(image_list_file, dict_test):        #label資料,圖檔位置\n","    f = open(image_list_file, 'w')\n","    filenames = []\n","    labels = []\n","\n","    for line in f:\n","        filename, label = line[:-1].split(',')\n","        filename = dict_test+filename\n","        filenames.append(filename)\n","        labels.append(int(label))\n","        \n","    return filenames, labels\n","\n","\n","def getvalbatch(resdict, labels, glen1):\n","    global b_count2, seq2\n","    b_count = b_count2\n","    idx = (b_count*batch_size)%glen1\n","    bx=[]\n","    by=[]\n","    for i in range(batch_size):\n","      #---------opencv read img & reshape\n","      bx.append(resdict)\n","      by.append(labels)\n","      #---------\n","      \n","    \n","    bx = np.reshape(np.asarray(bx), [batch_size, 256, 256, 3])\n","    by = np.asarray(by)\n","    b_count2 +=1\n","    return bx, by\n","  \n","def getbatch(resdict2, labels, glen1):\n","    global b_count, seq1\n","    idx = (b_count*batch_size)%glen1\n","    bx=[]\n","    by=[]\n","    for i in range(batch_size):\n","      #---------opencv read img & reshape\n","      bx.append(resdict2)\n","      by.append(labels)\n","      #---------\n","    \n","    \n","    bx = np.reshape(np.asarray(bx), [batch_size, 256, 256, 3])\n","    by = np.asarray(by)\n","    b_count +=1\n","    return bx, by\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h7AtFd4czh0W","colab":{}},"source":["# Training setting\n","batch_size =20\n","display_step = 400\n","n_classes = 100 # # of classes\n","dropout = 0.8# Dropout rate"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sFne_XH4E3An","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OO8R-S7SE49P","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7LCc7xsQzh0Y","outputId":"2de8cba1-8c2d-471d-8fc0-2a9f16e9c017","executionInfo":{"status":"ok","timestamp":1561227356670,"user_tz":-480,"elapsed":1222,"user":{"displayName":"Ziyitwo Zhuang","photoUrl":"","userId":"03996255233484029580"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["keep_prob = tf.placeholder(tf.float32)          # Dropout rate to be fed\n","learning_rate = tf.placeholder(tf.float32)      # Learning rate to be fed\n","tX = tf.placeholder(\"float\", [batch_size, 256, 256, 3]) # Training data batch\n","tY = tf.placeholder(\"int64\", [batch_size])            # Training label batch\n","lr = 1e-3                                    # Learning rate start\n","tst = tf.placeholder(tf.bool)\n","iter = tf.placeholder(tf.int32)\n","\n","trainlist, trainimagedir = train_image_label_list(\"drive/aoi/train3.txt\",\"drive/I_img_train\")\n","\n","dict1 = getimagedictandreshape(\"drive/I_img_train\")\n","labels= np.asarray(trainlist)\n","lab=str(labels)\n","data = np.asarray(dict1, np.float32)/255\n","glen1 = len(labels)\n","training_iters = glen1 * 1000\n","\n","testlist, testimagedir = test_image_filename_list(\"drive/aoi/test3.txt\",\"drive/I_img_test\")\n","\n","dict2 = getimagedictandreshape(\"drive/I_img_test\")\n","filenames= np.asarray(testlist)\n","data2 = np.asarray(dict2, np.float32)/255\n","tlen1 = len(filenames)\n","\n","\n","\n","\n","\n","    \n","\n","\n","\n","\n","#print(\"Total labels=%d\"%(max(lab)+1))\n","\n","print(\"Found %d training images & %d test images\"%(glen1, tlen1))\n","\n","pred = alex_net(tX,keep_prob,batch_size)\n","\n","cost = tf.losses.sparse_softmax_cross_entropy(labels=tY, logits=pred)\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n","correct_prediction = tf.equal(tf.argmax(pred, 1), tY)\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"],"execution_count":69,"outputs":[{"output_type":"stream","text":["Found 2528 training images & 10142 test images\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3CGfQ_Cbzh0c","outputId":"4e065bc9-6588-4622-932f-8d4935383d02","executionInfo":{"status":"error","timestamp":1561227359800,"user_tz":-480,"elapsed":853,"user":{"displayName":"Ziyitwo Zhuang","photoUrl":"","userId":"03996255233484029580"}},"colab":{"base_uri":"https://localhost:8080/","height":385}},"source":["saver = tf.train.Saver()\n","init = tf.global_variables_initializer()\n","with tf.Session() as sess:\n","    sess.run(init)\n","    step = 0\n","    while step * batch_size < training_iters:\n","        epoch1=np.floor((step*batch_size)/glen1)\n","        bx, by = getbatch(data, labels, glen1)\n","\n","        # Get a batch\n","        sess.run([optimizer],  feed_dict={tX:bx, tY:by, keep_prob: dropout, learning_rate: lr})\n","        \n","        if (step % 15000==1) & (step>15000):\n","            save_path = saver.save(sess, \"drive/checkpoint/tf_alex_model_iter\" + str(step) + \".ckpt\")\n","            print(\"Model saved in file at iteration %d: %s\" % (step*batch_size,save_path))\n","\n","        if step % display_step == 1:\n","            # calculate the loss\n","            tbx, tby = getvalbatch(data2, labels2, tlen1)\n","            loss = sess.run(cost, feed_dict={tX:bx, tY:by, keep_prob: 1., tst:True, iter:step})\n","            acc = sess.run(accuracy, feed_dict={tX:bx, tY:by,keep_prob: 1., tst:True, iter:step})\n","            acc2 = []\n","            for j in range(int(tlen1 / batch_size)):\n","              acc2.append(sess.run(accuracy, feed_dict={tX:tbx, tY:tby,keep_prob: 1., tst:True, iter:step}))\n","            acc2 = np.mean(acc2)\n","            \n","            print(\"Iter=%d/epoch=%d, Loss=%.6f, Training Accuracy=%.6f, Test Accuracy=%.6f, lr=%f\" % (step*batch_size, epoch1 ,loss, acc, acc2, lr))\n","\n","        step += 1\n","    print(\"Optimization Finished!\")\n","    save_path = saver.save(sess, \"drive/checkpoint/tf_alex_model.ckpt\")\n","print(\"Model saved in file: %s\" % save_path)"],"execution_count":70,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-c3bcddc9afb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtraining_iters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mepoch1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mglen1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglen1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Get a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-67-15c11765c679>\u001b[0m in \u001b[0;36mgetbatch\u001b[0;34m(resdict2, labels, glen1)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mbx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mb_count\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    290\u001b[0m            [5, 6]])\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 20 into shape (20,256,256,3)"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AOQOeejKzh0f","colab":{}},"source":["exit()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sr0obIo2zh0g","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}